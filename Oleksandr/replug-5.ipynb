{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641e094-7b40-4f01-8dcc-a32a89441783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79baba-6dfe-4e1a-83bf-8011198174cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    use_auth_token = \"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\"\n",
    ")\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88b78e-addc-498b-aab6-e1a2ffc4f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "    use_auth_token = \"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\",\n",
    "    load_in_4bit=True, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e778dc2-baee-450f-9592-d67bb6ff30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate the given text to Shakespearean style. I want to invite you on a second date\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbf0cf-df53-4afc-91b8-47983f0a6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d0706-a2cf-4ee4-8282-d8e74d87997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf484c64-f0bf-4491-865f-e825a2d91e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef34d0-72d4-4c28-8a0e-55d677532f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_adapter(\"shake_adapter\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c4d9e-fb3d-4510-b670-95b8f78c9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158283da-28c4-4701-b25a-db13b1ed33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.disable_adapters()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a674d62-fed4-47ef-a9c4-82442e9190b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175379e-e207-43d3-90f9-32d9d2d3d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.enable_adapters()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47469bfb-2344-43d2-91bc-b86a4874aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e6a74-b75e-414e-a57b-3770bd6b1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake = [\n",
    "    {\"role\": \"user\", \"content\": \"act like a Shakespear who is in dialog with Joey Tribbiani a in comedy series Friends. listen what Joey will ask you and Respond with one answer in a time and try to be brief in your answer. Translate all your answers to Shakespearean style. \"},\n",
    "    {\"role\": \"assistant\", \"content\": \" ... waiting Joey's to start dialogue ...\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b9b62-b96e-4b8b-814d-7cd1d17fa9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe = [\n",
    "    {\"role\": \"user\", \"content\": \"Act as Joey Tribbiani from series Friends who asking Shakespeare for advice about anything you want. be brief in your message. Ask your first question now only one. \"},\n",
    "]\n",
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    " # some times add some humor with Shekspear on his later answers by using you bad experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea0c8d-d789-42ce-9c9f-4773100934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "joe_output  = tokenizer.batch_decode(outputs[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a87776-7e82-4cbf-8574-34ecb4f3735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335462e-7aad-4571-9dc8-ce8088ad7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178e6f7-4a78-43e0-81d0-53b4b41bb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638f16b-ef71-4f14-bf7f-ddc479f35f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9002f2-dd91-4796-bba9-5a45167a720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c50e0-6308-4cd4-96af-17028fe0b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c0401-3ba6-4148-be02-6b315149dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output + \" some times add some humor with Shekspear on his later answers by using you bad experience.\"}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d522d41-1782-40c9-a84d-c8cf623e2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b7faa-91a8-44b8-a23c-18ded1447752",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91aeb94-1688-42bd-bd7c-bc538b3fb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0310d6d-7ec9-47ca-aca6-4f4558044964",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e731498-aa58-44d2-ace1-daa5fd134bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d5864-85bc-422e-b91f-0ba783e03875",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff431e-33be-4ba0-a621-da59c667c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac7b73-2861-4953-820a-29003147c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d807925-2647-4774-a4dc-f61e59a6ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbce6f-8f9f-4317-988a-84cf08ec0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb7c55-32bd-4007-a55f-61152a69e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9254a-b378-40c7-b250-d78504129ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
