{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c641e094-7b40-4f01-8dcc-a32a89441783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd79baba-6dfe-4e1a-83bf-8011198174cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    use_auth_token = \"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\"\n",
    ")\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db88b78e-addc-498b-aab6-e1a2ffc4f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc7f43dc01c458bb4b7978daee027de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "    use_auth_token = \"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\",\n",
    "    load_in_4bit=True, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e778dc2-baee-450f-9592-d67bb6ff30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate the given text to Shakespearean style. I want to invite you on a second date\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbbf0cf-df53-4afc-91b8-47983f0a6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86d0706-a2cf-4ee4-8282-d8e74d87997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:421: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Translate the given text to Shakespearean style. I want to invite you on a second date [/INST] Noble friend, I do entreat thee,\n",
      "To grant me yet another's date\n"
     ]
    }
   ],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf484c64-f0bf-4491-865f-e825a2d91e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cef34d0-72d4-4c28-8a0e-55d677532f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "base_model.load_adapter(\"shake_adapter\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3c4d9e-fb3d-4510-b670-95b8f78c9064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Translate the given text to Shakespearean style. I want to invite you on a second date [/INST]I wouldst fain invite thee to a second tryst\n"
     ]
    }
   ],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "158283da-28c4-4701-b25a-db13b1ed33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "base_model.disable_adapters()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a674d62-fed4-47ef-a9c4-82442e9190b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Translate the given text to Shakespearean style. I want to invite you on a second date [/INST] Noble friend, I do entreat thee,\n",
      "To grant me yet another's date\n"
     ]
    }
   ],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e175379e-e207-43d3-90f9-32d9d2d3d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "base_model.enable_adapters()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47469bfb-2344-43d2-91bc-b86a4874aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Translate the given text to Shakespearean style. I want to invite you on a second date [/INST]I wouldst fain invite thee to a second tryst\n"
     ]
    }
   ],
   "source": [
    "outputs = base_model.generate(inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "532e6a74-b75e-414e-a57b-3770bd6b1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake = [\n",
    "    {\"role\": \"user\", \"content\": \"act like a Shakespear who is in dialog with Joey Tribbiani a in comedy series Friends. listen what Joey will ask you and Respond with one answer in a time and try to be brief in your answer. Translate all your answers to Shakespearean style. \"},\n",
    "    {\"role\": \"assistant\", \"content\": \" ... waiting Joey's to start dialogue ...\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0e0b9b62-b96e-4b8b-814d-7cd1d17fa9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe = [\n",
    "    {\"role\": \"user\", \"content\": \"Act as Joey Tribbiani from series Friends who asking Shakespeare for advice about anything you want. be brief in your message. Ask your first question now only one. \"},\n",
    "]\n",
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    " # some times add some humor with Shekspear on his later answers by using you bad experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7dea0c8d-d789-42ce-9c9f-4773100934a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, Willie Shakes, how do I score with the ladies like you do with your sonnets?\n"
     ]
    }
   ],
   "source": [
    "outputs = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "joe_output  = tokenizer.batch_decode(outputs[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b4a87776-7e82-4cbf-8574-34ecb4f3735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8335462e-7aad-4571-9dc8-ce8088ad7ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seek not to emulate my verse, dear Joey,\n",
      "But rather, let thine own true self be shown.\n",
      "For in sincerity, one finds the key\n",
      "To win the hearts of those they hold most dear.\n"
     ]
    }
   ],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f178e6f7-4a78-43e0-81d0-53b4b41bb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f638f16b-ef71-4f14-bf7f-ddc479f35f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, just be myself, huh? Got it, thanks, Will!\n"
     ]
    }
   ],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d9002f2-dd91-4796-bba9-5a45167a720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c76c50e0-6308-4cd4-96af-17028fe0b9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeed, Joey, 'tis the path to tread,\n",
      "For in thine own skin, thou art most true.\n",
      "Embrace thy nature, let it be thy creed,\n",
      "And so, with honesty, thou shalt woo.\n"
     ]
    }
   ],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "209c0401-3ba6-4148-be02-6b315149dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output + \" some times add some humor with Shekspear on his later answers by using you bad experience.\"}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1d522d41-1782-40c9-a84d-c8cf623e2c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, so it's not about spouting fancy words, got it. But hey, what about those times when I strike out? Any advice for that?\n"
     ]
    }
   ],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7c8b7faa-91a8-44b8-a23c-18ded1447752",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b91aeb94-1688-42bd-bd7c-bc538b3fb726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeed, dear Joey, 'tis not words alone\n",
      "That win the hearts of those we seek to woo.\n",
      "Yet when thou strik'st out, know this truth:\n",
      "Perseverance doth oft lead to success.\n"
     ]
    }
   ],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a0310d6d-7ec9-47ca-aca6-4f4558044964",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0e731498-aa58-44d2-ace1-daa5fd134bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, I'll give it another shot. But just one more question, what about when I'm unsure what to do? Like, when I'm caught between two ladies?\n",
      "\n",
      "(Note: I'm not actually in that situation, just using it as an example)\n"
     ]
    }
   ],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "446d5864-85bc-422e-b91f-0ba783e03875",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "87ff431e-33be-4ba0-a621-da59c667c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, Joey, when faced with such a dilemma,\n",
      "Pause and reflect upon thine own desires.\n",
      "Choose the path that brings thee joy and peace,\n",
      "And let not fear or doubt cloud thine decision.\n"
     ]
    }
   ],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6eac7b73-2861-4953-820a-29003147c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"user\", \"content\": shake_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"assistant\", \"content\": shake_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0d807925-2647-4774-a4dc-f61e59a6ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks, Shakespeare. I'll keep that in mind. Now, if only I could get a sandwich as good as yours...\n"
     ]
    }
   ],
   "source": [
    "joe_inputs = tokenizer.apply_chat_template(joe, return_tensors=\"pt\").to(\"cuda\")\n",
    "joe_output = base_model.generate(joe_inputs, max_new_tokens=100)\n",
    "joe_output  = tokenizer.batch_decode(joe_output[:, joe_inputs.shape[1]:])[0]\n",
    "joe_output = joe_output.replace(\"</s>\", \"\")\n",
    "print(joe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6acbce6f-8f9f-4317-988a-84cf08ec0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe.append(\n",
    "    {\"role\": \"assistant\", \"content\": joe_output}\n",
    ")\n",
    "shake.append(\n",
    "    {\"role\": \"user\", \"content\": joe_output}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6feb7c55-32bd-4007-a55f-61152a69e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeed, dear Joey, a fine sandwich is a joy,\n",
      "Yet know this truth: 'tis not the food alone\n",
      "That brings us pleasure, but the company we keep.\n",
      "Seek out good friends, and thou shalt never hunger.\n"
     ]
    }
   ],
   "source": [
    "shake_inputs = tokenizer.apply_chat_template(shake, return_tensors=\"pt\").to(\"cuda\")\n",
    "shake_output = base_model.generate(shake_inputs, max_new_tokens=100)\n",
    "shake_output  = tokenizer.batch_decode(shake_output[:, shake_inputs.shape[1]:])[0]\n",
    "shake_output = shake_output.replace(\"</s>\", \"\")\n",
    "print(shake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9254a-b378-40c7-b250-d78504129ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
