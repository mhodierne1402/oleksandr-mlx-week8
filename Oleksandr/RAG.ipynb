{"cells":[{"cell_type":"markdown","metadata":{},"source":["PIP"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ! wget -P ~/ https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","# ! chmod +x ~/Miniconda3-latest-Linux-x86_64.sh\n","# ! ~/Miniconda3-latest-Linux-x86_64.sh -b\n","# ! export PATH=~/miniconda3/bin:$PATH\n","# ! conda init & conda config --set auto_activate_base false\n","# # close and start a new session\n","# ! conda activate base\n","# ! conda install cudatoolkit=11.0 -y\n","# !pip install sentence-transformers   transformers datasets peft accelerate bitsandbytes faiss-cpu faiss-gpu"]},{"cell_type":"markdown","metadata":{},"source":["Imports"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: mps\n"]}],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n","from sentence_transformers import SentenceTransformer, util\n","import faiss\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n","    device = torch.device(\"mps\")\n","elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")  # Fall back to CPU\n","\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    validation: Dataset({\n","        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n","        num_rows: 101093\n","    })\n","    train: Dataset({\n","        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n","        num_rows: 808731\n","    })\n","    test: Dataset({\n","        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n","        num_rows: 101092\n","    })\n","})\n"]}],"source":["dataset = load_dataset('ms_marco', 'v2.1')\n","print(dataset)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["134\n"]}],"source":["train_dataset = dataset['train'].select(range(1000))\n","filtered_train_dataset = train_dataset.filter(lambda example: example['wellFormedAnswers'] != [] and example['wellFormedAnswers'] != \"\")\n","print(len(filtered_train_dataset))"]},{"cell_type":"markdown","metadata":{},"source":["Unique Documents List"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1333\n"]}],"source":["unique_passages = set()\n","for row in filtered_train_dataset:\n","    unique_passages.update(row['passages']['passage_text'])\n","print(len(unique_passages))\n","documents = list(unique_passages)"]},{"cell_type":"markdown","metadata":{},"source":["HUgginface login"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /Users/a.diudiun/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"markdown","metadata":{},"source":["Load SentenceTransformer"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# SentenceTransformer(\"all-MiniLM-L6-v2\")\n","SentenceTranformer = SentenceTransformer(\n","    'sentence-transformers/msmarco-bert-base-dot-v5',\n","    device = device,\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["Test SentenceTransformer"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["embedding length:  768\n","Similarity: tensor([[166.5561, 159.5406]])\n"]}],"source":["query_embedding = SentenceTranformer.encode('How big is London')\n","print(\"embedding length: \", len(query_embedding))\n","document_embedding = SentenceTranformer.encode(\n","    [\n","        'London has 9,787,426 inhabitants at the 2011 census',\n","        'London is known for its finacial district',\n","    ])\n","\n","print(\"Similarity:\", util.dot_score(query_embedding, document_embedding))\n"]},{"cell_type":"markdown","metadata":{},"source":["Generate Embeddings from all documents"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 14/14 [00:14<00:00,  1.00s/it]\n"]}],"source":["# Encode documents\n","document_embeddings = SentenceTranformer.encode(\n","    documents, \n","    show_progress_bar=True, \n","    device = device,\n","    batch_size=100\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Create Faiss Index from all documents"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["# Build Faiss index\n","# index = faiss.IndexFlatL2(document_embeddings.shape[1])  # L2 distance\n","faiss.normalize_L2(document_embeddings)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["index = faiss.IndexFlatIP(document_embeddings.shape[1])  # L2 distance\n","index.add(document_embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["Store Faiss index to storage and read from storage"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["# Save the index to a file\n","faiss.write_index(index, \"index_docs.index\")\n","# Load the index from a file\n","# index = faiss.read_index(\"index_docs.index\")"]},{"cell_type":"markdown","metadata":{},"source":["Test Faiss Index"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.8906977  0.88991797 0.88836265 0.88797027 0.8852686 ]]\n","[[ 389 1179  701   52  615]]\n","Softmax\n","tensor([[0.2005, 0.2003, 0.2000, 0.1999, 0.1994]])\n","Most similar documents to the query:\n","Rank 1: Definition of exhibit. 1  transitive verb. 2  1 : to submit (as a document) to a court or officer in course of proceedings; also : to present or offer officially or in legal form.\n","Rank 2: Definition of exhibit. 1  1 : a document or material object produced and identified in court or before an examiner for use as evidence. 2  2 : something exhibited. 3  3 : an act or instance of exhibiting : exhibition.\n","Rank 3: Quick Answer. The abbreviation et al. is short for the Latin phrase et alia, meaning and others.. When it appears on a property deed, it indicates that a list of items or persons named on the deed includes others as well. Continue Reading.\n","Rank 4: et al. n. abbreviation for the Latin phrase et alii meaning and others.. This is commonly used in shortening the name of a case, as in Pat Murgatroyd v. Sally Sherman, et al.. et al. adverb and all, and everyone, and more of the same, and other parties, and other things, and others, and the rest.\n","Rank 5: A pictograph is a picture or image that represents a word or a phrase. Anything that conveys information using just pictures can be called a pictograph. When you click on an icon on your computer, that's a pictograph, and when you text an emoji to your friend, that's another kind of pictograph.\n"]}],"source":["# Query\n","query = \"This is a query document.\"\n","query_embedding = SentenceTranformer.encode([query])\n","\n","# Perform document similarity search\n","faiss.normalize_L2(query_embedding)\n","k = 5  # Number of similar documents to retrieve\n","D, I = index.search(query_embedding, k)\n","\n","print(D)\n","print(I)\n","# for d in D:\n","#     print((d-11.71897)*1000)\n","# Print similar documents\n","D_tensor = torch.tensor(D)\n","D_softmax = F.softmax(D_tensor, dim=1)  # Apply softmax along the rows\n","# D_softmax_neg = F.softmax(-D_tensor, dim=1)  # Apply softmax along the rows\n","\n","print(\"Softmax\")\n","print(D_softmax)\n","# print(D_softmax_neg)\n","# Convert softmax result back to numpy array\n","D_softmax_np = D_softmax.numpy()\n","\n","print(\"Most similar documents to the query:\")\n","for i, idx in enumerate(I[0]):\n","    print(f\"Rank {i+1}: {documents[idx]}\")"]},{"cell_type":"markdown","metadata":{},"source":["Configure LoRA and sentenceTranformer of query"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","QueryTranformer = SentenceTransformer(\n","    'sentence-transformers/msmarco-bert-base-dot-v5',\n","    device = device,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define sentenceTransformer in training mode "]},{"cell_type":"markdown","metadata":{},"source":["Define LoRA and EncoderDecoder GPT2 "]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["from transformers import GPT2Model, GPT2Tokenizer\n","# Generator = GPT2Model.from_pretrained('gpt2')\n","# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","Generator = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", padding_side='left')"]},{"cell_type":"markdown","metadata":{},"source":["Define GPT2 in training mode"]},{"cell_type":"markdown","metadata":{},"source":["Define custom lost function???\n"]},{"cell_type":"markdown","metadata":{},"source":["Create training object combined????"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'str' object is not callable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[PAD]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      5\u001b[0m     train_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      6\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m targets \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     14\u001b[0m     train_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwellFormedAnswers\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     15\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n","\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"]}],"source":["# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","tokenizer.pad_token(\"[PAD]\")\n","\n","inputs = tokenizer(\n","    train_dataset['query'], \n","    max_length=512, \n","    padding='max_length', \n","    truncation=True, \n","    pad_token = tokenizer.pad_token, \n","    return_tensors='pt'\n",")\n","\n","targets = tokenizer(\n","    train_dataset['wellFormedAnswers'], \n","    max_length=512, \n","    padding='max_length', \n","    truncation=True, \n","    pad_token = tokenizer.pad_token, \n","    return_tensors='pt'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def custom_loss(logits, labels):\n","    loss = torch.mean((logits - labels) ** 2)  # For example, mean squared error\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class QueryDataset(Dataset):\n","    def __init__(self, tokenizer, data):\n","        self.queries = data['query']\n","        self.answers = data['wellPreparedAnswer']\n","        self.device = device\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.queries)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'query_ids': torch.tensor(self.tokenizer.encode(self.queries[idx]), dtype=torch.float),\n","            'answer_ids': torch.tensor(self.tokenizer.encode(self.answers[idx]), dtype=torch.float),\n","            'query': self.queries[idx],\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["K = 2\n","batch_size = 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TrainingDataset = QueryDataset(tokenizer, train_dataset)\n","TrainingDataloader = DataLoader(TrainingDataset, batch_size, shuffle=False, collate_fn=collate_fn)  \n","\n","# item.toDevice(de)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["class CustomModel(torch.nn.Module):\n","    def __init__(self, EncoderDecoder, index, documents):\n","        super().__init__()\n","        self.EncoderDecoder = EncoderDecoder\n","        self.QueryTranformer = QueryTranformer\n","        self.documents = documents\n","        self.index = index\n","\n","    def forward(self, Q, K):\n","        query_embedding = self.QueryTranformer.encode([Q])  # Pass appropriate inputs\n","\n","        D, I = index.search(query_embedding, K)\n","        D_tensor = torch.tensor(D)\n","        D_softmax = F.softmax(D_tensor, dim=1) \n","\n","        # tensor zero [Batch, K, seq_len]\n","\n","        decoder_outputs = []\n","        for i, idx in enumerate(I[0]):\n","            input_text = self.documents[idx] + \" \" + Q\n","            input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","            \n","        decoder_output = self.EncoderDecoder(\n","            input_ids=input_ids\n","        )\n","\n","        decoder_outputs.append(decoder_output)\n","\n","\n","        # run decoder on K documents and Q \n","        # avarage output from decoder \n","        return gpt2_output, sentence_embedding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.pop(\"labels\")\n","        outputs = CustomModel(**inputs)\n","        logits = outputs.logits\n","        loss = custom_loss(logits, labels)\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your model, tokenizer, and training arguments\n","model = ...  # Define your model here\n","tokenizer = ...  # Define your tokenizer here\n","training_args = TrainingArguments(\n","    ...\n",")  # Define your training arguments here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer = CustomTrainer(\n","    modelok=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tenizer,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["Inference test data"]},{"cell_type":"markdown","metadata":{},"source":["Store model"]},{"cell_type":"markdown","metadata":{},"source":["Build API "]},{"cell_type":"markdown","metadata":{},"source":["Pack to Docker Container"]},{"cell_type":"markdown","metadata":{},"source":["Publish"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Select and Prepare a Pre-trained Seq2Seq Model\n","# Generate the Response\n","# Evaluation and Iteration\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
