{"cells":[{"cell_type":"markdown","metadata":{},"source":["PIP"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ! wget -P ~/ https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","# ! chmod +x ~/Miniconda3-latest-Linux-x86_64.sh\n","# ! ~/Miniconda3-latest-Linux-x86_64.sh -b\n","# ! export PATH=~/miniconda3/bin:$PATH\n","# ! conda init & conda config --set auto_activate_base false\n","# # close and start a new session\n","# ! conda activate base\n","# ! conda install cudatoolkit=11.0 -y\n","# !pip install sentence-transformers   transformers datasets peft accelerate bitsandbytes faiss-cpu faiss-gpu"]},{"cell_type":"markdown","metadata":{},"source":["Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n","Using device: mps\n"]},{"name":"stderr","output_type":"stream","text":["/opt/homebrew/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n","  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"]}],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n","from sentence_transformers import SentenceTransformer, util\n","import faiss\n","import pandas as pd\n","import torch\n","\n","if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n","    device = torch.device(\"mps\")\n","elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")  # Fall back to CPU\n","\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    validation: Dataset({\n","        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n","        num_rows: 101093\n","    })\n","    train: Dataset({\n","        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n","        num_rows: 808731\n","    })\n","    test: Dataset({\n","        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n","        num_rows: 101092\n","    })\n","})\n"]}],"source":["dataset = load_dataset('ms_marco', 'v2.1')\n","print(dataset)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["134\n"]}],"source":["train_dataset = dataset['train'].select(range(1000))\n","filtered_train_dataset = train_dataset.filter(lambda example: example['wellFormedAnswers'] != [] and example['wellFormedAnswers'] != \"\")\n","print(len(filtered_train_dataset))"]},{"cell_type":"markdown","metadata":{},"source":["Unique Documents List"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1333\n"]}],"source":["unique_passages = set()\n","for row in filtered_train_dataset:\n","    unique_passages.update(row['passages']['passage_text'])\n","print(len(unique_passages))\n","documents = list(unique_passages)"]},{"cell_type":"markdown","metadata":{},"source":["HUgginface login"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /Users/a.diudiun/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"markdown","metadata":{},"source":["Load SentenceTransformer"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# SentenceTransformer(\"all-MiniLM-L6-v2\")\n","SentenceTranformer = SentenceTransformer(\n","    'sentence-transformers/msmarco-bert-base-dot-v5',\n","    device = device,\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["Test SentenceTransformer"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["embedding length:  768\n","Similarity: tensor([[166.5561, 159.5406]])\n"]}],"source":["query_embedding = SentenceTranformer.encode('How big is London')\n","print(\"embedding length: \", len(query_embedding))\n","document_embedding = SentenceTranformer.encode(\n","    [\n","        'London has 9,787,426 inhabitants at the 2011 census',\n","        'London is known for its finacial district',\n","    ])\n","\n","print(\"Similarity:\", util.dot_score(query_embedding, document_embedding))\n"]},{"cell_type":"markdown","metadata":{},"source":["Generate Embeddings from all documents"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 14/14 [00:14<00:00,  1.00s/it]\n"]}],"source":["# Encode documents\n","document_embeddings = SentenceTranformer.encode(\n","    documents, \n","    show_progress_bar=True, \n","    device = device,\n","    batch_size=100\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Create Faiss Index from all documents"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# Build Faiss index\n","# index = faiss.IndexFlatL2(document_embeddings.shape[1])  # L2 distance\n","faiss.normalize_L2(document_embeddings)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["index = faiss.IndexFlatIP(document_embeddings.shape[1])  # L2 distance\n","index.add(document_embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["Store Faiss index to storage and read from storage"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# Save the index to a file\n","faiss.write_index(index, \"index_docs.index\")\n","# Load the index from a file\n","# index = faiss.read_index(\"index_docs.index\")"]},{"cell_type":"markdown","metadata":{},"source":["Test Faiss Index"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[11.790841  11.7805195 11.759927  11.754736  11.71897   11.717907\n","  11.711843  11.70236   11.696595  11.674039 ]]\n","Most similar documents to the query:\n","Rank 1: Definition of exhibit. 1  transitive verb. 2  1 : to submit (as a document) to a court or officer in course of proceedings; also : to present or offer officially or in legal form.\n","Rank 2: Definition of exhibit. 1  1 : a document or material object produced and identified in court or before an examiner for use as evidence. 2  2 : something exhibited. 3  3 : an act or instance of exhibiting : exhibition.\n","Rank 3: Quick Answer. The abbreviation et al. is short for the Latin phrase et alia, meaning and others.. When it appears on a property deed, it indicates that a list of items or persons named on the deed includes others as well. Continue Reading.\n","Rank 4: et al. n. abbreviation for the Latin phrase et alii meaning and others.. This is commonly used in shortening the name of a case, as in Pat Murgatroyd v. Sally Sherman, et al.. et al. adverb and all, and everyone, and more of the same, and other parties, and other things, and others, and the rest.\n","Rank 5: A pictograph is a picture or image that represents a word or a phrase. Anything that conveys information using just pictures can be called a pictograph. When you click on an icon on your computer, that's a pictograph, and when you text an emoji to your friend, that's another kind of pictograph.\n","Rank 6: * Source material, data, and tables are provided by the Bureau of Labor Statistics, Department of Labor, and OSHA's Area Offices.\n","Rank 7: Canadian Postal Code Database. Get all Canadian Postal Codes and their information in one easy to use database. 2010 Census Database. Get the 2010 Census data in an easy to use format for all summary levels: National, State, COunty, City, and Congressional District.\n","Rank 8: Meaning of the name Nyla, analysis of the name Nyla and so much more… What does Nyla mean and its numerology, definition, origin, popularity and very interesting information. Please use the menu below. Quick Menu.\n","Rank 9: Use 'pictograph' in a Sentence. When using a pictograph, you are presenting a visual account of something to show progression, division, decrease in productivity, peaks and valleys, actually anything you like can be displayed and analyzed.\n","Rank 10: The Parliamentary form of government is also known as the Cabinet system or Cabinet Form of Government because the cabinet is the link between the two departments. It is also called a responsible government because executive department is responsible and answerable to the legislative department.n a Parliamentary system the legislative and the executive department of the government are very closely related and are interdependent for the performance of governmental functions.\n"]}],"source":["# Query\n","query = \"This is a query document.\"\n","query_embedding = SentenceTranformer.encode([query])\n","\n","# Perform document similarity search\n","k = 10  # Number of similar documents to retrieve\n","D, I = index.search(query_embedding, k)\n","\n","print(D)\n","# Print similar documents\n","\n","\n","print(\"Most similar documents to the query:\")\n","for i, idx in enumerate(I[0]):\n","    print(f\"Rank {i+1}: {documents[idx]}\")"]},{"cell_type":"markdown","metadata":{},"source":["Configure LoRA and sentenceTranformer of query"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","QueryTranformer = SentenceTransformer(\n","    'sentence-transformers/msmarco-bert-base-dot-v5',\n","    device = device,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define sentenceTransformer in training mode "]},{"cell_type":"markdown","metadata":{},"source":["Define LoRA and EncoderDecoder GPT2 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import GPT2Model, GPT2Tokenizer\n","# EncoderDecoder = GPT2Model.from_pretrained('gpt2')\n","EncoderDecoder = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", padding_side='left')"]},{"cell_type":"markdown","metadata":{},"source":["Define GPT2 in training mode"]},{"cell_type":"markdown","metadata":{},"source":["Define custom lost function???\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def custom_loss(logits, labels):\n","    loss = torch.mean((logits - labels) ** 2)  # For example, mean squared error\n","    return loss"]},{"cell_type":"markdown","metadata":{},"source":["Create training object combined????"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["K = 2"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["class CustomModel(torch.nn.Module):\n","    def __init__(self, EncoderDecoder, index, documents):\n","        super().__init__()\n","        self.EncoderDecoder = EncoderDecoder\n","        self.QueryTranformer = QueryTranformer\n","        self.documents = documents\n","        self.index = index\n","\n","    def forward(self, Q, K):\n","        query_embedding = self.QueryTranformer.encode([Q])  # Pass appropriate inputs\n","\n","        D, I = index.search(query_embedding, K)\n","\n","        for i, idx in enumerate(I[0]):\n","            input_text = self.documents[idx] + \" \" + Q\n","            input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","            \n","            decoder_output = self.EncoderDecoder(\n","                input_ids=input_ids\n","            )\n","\n","\n","        # run decoder on K documents and Q \n","        # avarage output from decoder \n","        return gpt2_output, sentence_embedding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.pop(\"labels\")\n","        outputs = CustomModel(**inputs)\n","        logits = outputs.logits\n","        loss = custom_loss(logits, labels)\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define your model, tokenizer, and training arguments\n","model = ...  # Define your model here\n","tokenizer = ...  # Define your tokenizer here\n","training_args = TrainingArguments(\n","    ...\n",")  # Define your training arguments here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer = CustomTrainer(\n","    modelok=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tenizer,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Run Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["Inference test data"]},{"cell_type":"markdown","metadata":{},"source":["Store model"]},{"cell_type":"markdown","metadata":{},"source":["Build API "]},{"cell_type":"markdown","metadata":{},"source":["Pack to Docker Container"]},{"cell_type":"markdown","metadata":{},"source":["Publish"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Select and Prepare a Pre-trained Seq2Seq Model\n","# Generate the Response\n","# Evaluation and Iteration\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
