{"cells":[{"cell_type":"markdown","metadata":{},"source":["PIP"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ! wget -P ~/ https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","# ! chmod +x ~/Miniconda3-latest-Linux-x86_64.sh\n","# ! ~/Miniconda3-latest-Linux-x86_64.sh -b\n","# ! export PATH=~/miniconda3/bin:$PATH\n","# ! conda init & conda config --set auto_activate_base false\n","# # close and start a new session\n","# ! conda activate base\n","# ! conda install cudatoolkit=11.0 -y\n","# !pip install sentence-transformers   transformers datasets peft accelerate bitsandbytes faiss-cpu faiss-gpu"]},{"cell_type":"markdown","metadata":{},"source":["Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n","from sentence_transformers import SentenceTransformer, util\n","import faiss\n","import pandas as pd\n","import torch\n","\n","if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n","    device = torch.device(\"mps\")\n","elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")  # Fall back to CPU\n","\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = load_dataset('ms_marco', 'v1.1')\n","print(dataset)\n","train_dataset = dataset['train']\n","test_dataset = dataset['test']"]},{"cell_type":"markdown","metadata":{},"source":["Unique Documents List"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Assuming dataframe is your DataFrame containing passages\n","print(train_dataset['passages'][:1])\n","# passages_list = train_dataset['passages']['passage_text'].tolist()\n","\n","unique_passages = set()\n","for row in train_dataset:\n","    unique_passages.update(row['passages']['passage_text'])\n","print(len(unique_passages))\n","documents = list(unique_passages)"]},{"cell_type":"markdown","metadata":{},"source":["HUgginface login"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"markdown","metadata":{},"source":["Load SentenceTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SentenceTransformer(\"all-MiniLM-L6-v2\")\n","SentenceTranformer = SentenceTransformer(\n","    'sentence-transformers/msmarco-bert-base-dot-v5',\n","    device = device,\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["Test SentenceTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query_embedding = SentenceTranformer.encode('How big is London')\n","print(len(query_embedding))\n","document_embedding = SentenceTranformer.encode(['London has 9,787,426 inhabitants at the 2011 census',\n","                                  'London is known for its finacial district'])\n","\n","print(\"Similarity:\", util.dot_score(query_embedding, document_embedding))\n"]},{"cell_type":"markdown","metadata":{},"source":["Generate Embeddings from all documents"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 6270/6270 [3:07:58<00:00,  1.80s/it]  \n"]}],"source":["# Encode documents\n","document_embeddings = SentenceTranformer.encode(\n","    documents, \n","    show_progress_bar=True, \n","    device = device,\n","    batch_size=100\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Create Faiss Index from all documents"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# Build Faiss index\n","# index = faiss.IndexFlatL2(document_embeddings.shape[1])  # L2 distance\n","faiss.normalize_L2(document_embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["Store Faiss index to storage and read from storage"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["index = faiss.IndexFlatIP(document_embeddings.shape[1])  # L2 distance\n","index.add(document_embeddings)\n","faiss.write_index(index, \"index_docs.index\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Test Faiss Index"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Most similar documents to the query:\n","Rank 1: A query language is a language in which a user requests information from the database. These languages are usually on a level higher than that of a standard programming lang … uage. Query languages can be categorized as either procedural or non procedural.\n","Rank 2: Overview. Structured Query Language (SQL) is a specialized language for updating, deleting, and requesting information from databases. SQL is an ANSI and ISO standard, and is the de facto standard database query language. \n","Rank 3: A system specification document is used to present the functions, performance and limitations of a software product or system.\n","Rank 4: The PUB Document file format. PUB is the file extension which is generally used by the Microsoft Publisher application which is a part of the Microsoft Office product set. This file format can comprise various objects such as graphics, images, formatted text, or any other kind of object. \n","Rank 5: Query Definition: Stored Procedures and Queries. The basic query object executes a single. statement. It is possible, however, to execute an SQL stored procedure instead. This greatly expands the selection, manipulation, and presentation that can be done through queries. The Query Object. There are two steps to defining a query that calls a stored procedure. The first is checking the Stored Procedure checkbox on the main tab of the Query object, and the second is providing the call in the Query String field.\n","Rank 6: Document (Microsoft Publisher). PUB is a file extension for a document file format used in Microsoft Publisher, a desktop publishing program that is a component of the Office product suite. Through Publisher, users can create, edit, publish, manage and share content. \n","Rank 7: System Specification Document. A system specification document is used to present the functions, performance and limitations of a software product or system. The document should contain an overview of the product which shall describe what the system is supposed to do and the jobs it will perform.\n","Rank 8: Document File. Description. The .pub file extension is the file extension used by the Microsoft Publisher application which forms part of the Microsoft Office product set. A .pub file can contain images, graphics, formatted text and other objects.\n","Rank 9: You can use and browse these files in the same way that you browse any table file because these files are actually tables. A table file consists of a header record and data records. The header record defines the structure of the table and contains any other information related to the table. \n","Rank 10: How can you tell if a document is a SOP, Procedure, or Work Instruction? Also, what are the connections between each of these documents? Is one more important than the other? \n"]}],"source":["# Query\n","query = \"This is a query document.\"\n","query_embedding = SentenceTranformer.encode([query])\n","\n","# Perform document similarity search\n","k = 10  # Number of similar documents to retrieve\n","D, I = index.search(query_embedding, k)\n","\n","print(D)\n","# Print similar documents\n","\n","\n","print(\"Most similar documents to the query:\")\n","for i, idx in enumerate(I[0]):\n","    print(f\"Rank {i+1}: {documents[idx]}\")"]},{"cell_type":"markdown","metadata":{},"source":["Configure LoRA and sentenceTranformer of query"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","QueryTranformer = SentenceTransformer(\n","    'sentence-transformers/msmarco-bert-base-dot-v5',\n","    device = device,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define sentenceTransformer in training mode "]},{"cell_type":"markdown","metadata":{},"source":["Define LoRA and EncoderDecoder GPT2 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import GPT2Model, GPT2Tokenizer\n","# EncoderDecoder = GPT2Model.from_pretrained('gpt2')\n","EncoderDecoder = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", padding_side='left')"]},{"cell_type":"markdown","metadata":{},"source":["Define GPT2 in training mode"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, AdamW\n","from sentence_transformers import SentenceTransformer\n","from peft import PeftModel, LoraConfig, prepare_model_for_kbit_training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n","lora_config = LoraConfig(lora_dim=32, lora_alpha=2, merge_weights=True)\n","peft_gpt2_model = PeftModel(gpt2_model, lora_config)\n","peft_gpt2_model = prepare_model_for_kbit_training(peft_gpt2_model, gpt2_config)\n","\n","# doc_embeddings = torch.load('doc_embeddings.pt')\n","# faiss_index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n","# faiss_index.add(doc_embeddings.numpy())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optimizer = AdamW(peft_gpt2_model.parameters(), lr=5e-5)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train(model, data_loader, epochs, device):\n","    model.train()\n","    model.to(device)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n","\n","    for epoch in range(epochs):\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)  # Shape [batch_size, num_documents, seq_length, vocab_size]\n","            labels = labels.to(device)  # Shape adjusted if necessary\n","\n","            batch_size, num_documents, seq_length, _ = inputs.shape\n","            loss_total = 0\n","\n","            for b in range(batch_size):\n","                for n in range(num_documents):\n","                    input_ids = inputs[b, n]  # Get input for one document\n","                    output_labels = labels[b]  # Assuming labels are shared across documents\n","\n","                    # Assuming your model can handle seq_length and vocab_size directly,\n","                    # otherwise adjust model input handling\n","                    outputs = model(input_ids)\n","                    loss = criterion(outputs.view(-1, outputs.shape[-1]), output_labels.view(-1))\n","                    loss.backward()\n","                    loss_total += loss.item()\n","\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            print(f\"Epoch {epoch}, Batch Loss: {loss_total / (batch_size * num_documents)}\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["What is the impact of climate change on polar bears? Climate change is reducing the overall extent and seasonal duration of sea ice, impacting the polar bear's ability to survive.reperepereperepereperepe Kingston Kingston apparently litres litres litres litresAnn) Bo Bo Programme Programme Programme Jim Jim Jim Jim transitioning Express Programme Programme Programme Programme Programme Programme Property Property Property PropertySSLSSLSSL apparentlyiologicaliologicaliologicaliologicalPowerPoweréeéeibus KHPowerxmlxml UNCLASSIFIED knees knees knees knees knees knees knees requests requests449SSLSSLSSLSSLSSLSSLSSLSSLSSL scr infrared pizz touchscreen US US US US US US US US US US US US US US US US US US US US US US goodwill goodwill goodwill goodwill goodwill Express badge badge vendors OmahaCt delic delic delic delic delic delic delic delic delic delic delic delic delic delic delicmanagementgradinggradinggradinggradinggrading Jim Jim eternityarticle vendors vendors vendors quant quant quant quant quant quant quant quant quant quant quant quant quant quant Jimionicionicionicionic175®®® US US US US US\n"]}],"source":["# Example query and document\n","query = \"What is the impact of climate change on polar bears?\"\n","\n","document = \"Climate change is reducing the overall extent and seasonal duration of sea ice, impacting the polar bear's ability to survive.\"\n","\n","model.eval()\n","\n","# Concatenate query with the document context\n","input_text = query + \" \" + document\n","\n","# Encode the text into tensor of integers using the tokenizer\n","input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","# Generate a response from the model\n","output = model.generate(input_ids, max_length=200, num_return_sequences=1)\n","\n","# Decode the output tensor to a string\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)"]},{"cell_type":"markdown","metadata":{},"source":["Define custom lost function???\n"]},{"cell_type":"markdown","metadata":{},"source":["Create training object combined????"]},{"cell_type":"markdown","metadata":{},"source":["Run Training"]},{"cell_type":"markdown","metadata":{},"source":["Inference test data"]},{"cell_type":"markdown","metadata":{},"source":["Store model"]},{"cell_type":"markdown","metadata":{},"source":["Build API "]},{"cell_type":"markdown","metadata":{},"source":["Pack to Docker Container"]},{"cell_type":"markdown","metadata":{},"source":["Publish"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Select and Prepare a Pre-trained Seq2Seq Model\n","# Generate the Response\n","# Evaluation and Iteration\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
