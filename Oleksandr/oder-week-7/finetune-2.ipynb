{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers datasets peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", load_in_4bit=True, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "tokenizer.pad_token = \"!\"\n",
    "CUTOFF_LEN = 256\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 2 * LORA_R\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(r=LORA_R, lora_alpha=LORA_ALPHA, target_modules=[ \"w1\", \"w2\", \"w3\"], lora_dropout=LORA_DROPOUT, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarot = load_dataset('barissglc/tarot', split = 'train')\n",
    "df = pd.read_csv('final_perfume_data.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "perfume = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card 1: Knight of Pentacles\n",
      "Card 2: Queen of Pentacles\n",
      "Card 3: Three of Swords\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def draw_tarot_cards():\n",
    "    tarot_cards = [\n",
    "        \"The Fool\", \"The Magician\", \"The High Priestess\", \"The Empress\", \"The Emperor\", \n",
    "        \"The Hierophant\", \"The Chariot\", \"The Lovers\", \"Strength\", \"The Hermit\", \n",
    "        \"The Wheel of Fortune\", \"Justice\", \"The Hanged Man\", \"Death\", \"Temperance\", \n",
    "        \"The Devil\", \"The Tower\", \"The Star\", \"The Moon\", \"The Sun\", \"Judgement\", \"The World\",\n",
    "        \"Ace of Wands\", \"Two of Wands\", \"Three of Wands\", \"Four of Wands\", \"Five of Wands\", \"Six of Wands\", \n",
    "        \"Seven of Wands\", \"Eight of Wands\", \"Nine of Wands\", \"Ten of Wands\", \"Page of Wands\", \"Knight of Wands\", \n",
    "        \"Queen of Wands\", \"King of Wands\",\n",
    "        \"Ace of Pentacles\", \"Two of Pentacles\", \"Three of Pentacles\", \"Four of Pentacles\", \"Five of Pentacles\", \n",
    "        \"Six of Pentacles\", \"Seven of Pentacles\", \"Eight of Pentacles\", \"Nine of Pentacles\", \"Ten of Pentacles\", \n",
    "        \"Page of Pentacles\", \"Knight of Pentacles\", \"Queen of Pentacles\", \"King of Pentacles\",\n",
    "        \"Ace of Swords\", \"Two of Swords\", \"Three of Swords\", \"Four of Swords\", \"Five of Swords\", \n",
    "        \"Six of Swords\", \"Seven of Swords\", \"Eight of Swords\", \"Nine of Swords\", \"Ten of Swords\", \n",
    "        \"Page of Swords\", \"Knight of Swords\", \"Queen of Swords\", \"King of Swords\",\n",
    "        \"Ace of Cups\", \"Two of Cups\", \"Three of Cups\", \"Four of Cups\", \"Five of Cups\", \n",
    "        \"Six of Cups\", \"Seven of Cups\", \"Eight of Cups\", \"Nine of Cups\", \"Ten of Cups\", \n",
    "        \"Page of Cups\", \"Knight of Cups\", \"Queen of Cups\", \"King of Cups\"\n",
    "    ]\n",
    "\n",
    "    # Shuffle the list of tarot cards\n",
    "    random.shuffle(tarot_cards)\n",
    "\n",
    "    # Draw the first three cards from the shuffled list\n",
    "    card1, card2, card3 = tarot_cards[:3]\n",
    "\n",
    "    return card1, card2, card3\n",
    "\n",
    "# Example usage:\n",
    "card1, card2, card3 = draw_tarot_cards()\n",
    "print(f\"Card 1: {card1}\")\n",
    "print(f\"Card 2: {card2}\")\n",
    "print(f\"Card 3: {card3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(user_query):\n",
    "  sys_msg = \"Imagine you are a professional Perfumer, come up with the notes of perfume based on the description\"\n",
    "  p = \"<s> [INST]\" + sys_msg +\"\\n\"+  user_query['Description'] + \"[/INST] \" +  str(user_query['Notes']) + \"</s>\"\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2191/2191 [00:01<00:00, 1345.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda prompt: tokenizer(prompt + tokenizer.eos_token, truncation=True, max_length=CUTOFF_LEN, padding=\"max_length\")\n",
    "# tarot_dataset = tarot.shuffle().map(lambda x: tokenize(generate_prompt(x)), remove_columns=['Description' , 'Notes'])\n",
    "perfume_dataset = perfume.shuffle().map(lambda x: tokenize(generate_prompt(x)), remove_columns=['Description' , 'Notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/tuesday/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  train_dataset=perfume_dataset,\n",
    "  args=TrainingArguments(\n",
    "    per_device_train_batch_size=40,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=2,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    output_dir=\"/root/model\"\n",
    "  ),\n",
    "  data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/tuesday/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 1:21:30, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.361300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.740400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.545900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.274200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.189400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.200600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.160100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/tuesday/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26, training_loss=2.4458052745232215, metrics={'train_runtime': 5083.5873, 'train_samples_per_second': 0.862, 'train_steps_per_second': 0.005, 'total_flos': 2.976603611930296e+17, 'train_loss': 2.4458052745232215, 'epoch': 1.89})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inference_prompt(user_query):\n",
    "  sys_msg = \"Imagine you are a professional Perfumer, come up with the notes of perfume based on the description\"\n",
    "  p = \"<s> [INST]\" + sys_msg +\"\\n\"+  user_query + \"[/INST]\"\n",
    "  return p\n",
    "\n",
    "def generate_optimization_prompt(user_query):\n",
    "  sys_msg = \"Imagine you are a professional Perfumer, come up with the description of perfume based on the description tarot reading but dont use general tarot mistery association stick stricly to description and be laconic\"\n",
    "  p = \"<s> [INST]\" + sys_msg +\"\\n\"+  user_query + \"[/INST]\"\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cards:\n",
      " The Nine of Pentacles , The Chariot , The Hermit\n",
      "\n",
      "\n",
      "Tarot Reading: \n",
      " The Nine of Pentacles indicates that you are in a place of abundance and security, and you are able to enjoy the fruits of your labor. The Chariot indicates that you are in a place of power and control, and you are able to take charge of your life and make the necessary changes to ensure that you are able to reach your goals. The Hermit indicates that you are in a place of contemplation and reflection, and you are able to take a step back and look at the bigger picture. You are able to see the opportunities that are available to you and you are able to make the necessary changes to ensure that you are able to reach your goals. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Perfume description:\n",
      " The Nine of Pentacles, The Chariot, and The Hermit are combined to create a scent that is rich, powerful, and contemplative. The Nine of Pentacles brings a sense of abundance and security, while The Chariot brings a sense of power and control. The Hermit brings a sense of contemplation and reflection, allowing you to see the opportunities available to you and make the necessary changes to reach your goals. This scent is a luxurious blend of sandalwood, amber, and musk, with a hint of spice and a touch of sweetness. It is a scent that is both powerful and contemplative, perfect for those who are in a place of abundance and security and are ready to take charge of their lives and make the necessary changes to reach their goals. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Perfume imgredients: \n",
      " Sandalwood, amber, musk, spice, sweetness \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# description = \" Could there ever be an aroma more blissful than removing a freshly-baked cake from the oven? The feeling of accomplishment for a job well done, the mouthwatering, sweet, warm smell that fills the room, the anticipation of that perfect first bite- it's heaven on earth. With Vanilla Cake, Montale invites you to enjoy that wondrous feeling every single day. This gourmand and bewitching fragrance recipe calls for blending milk, grilled almonds, warm caramel and vanilla for the ultimate meringue silllage. Creamy, sweet, toasty and rich, this is a perfect gourmand scent, the kind to leave a trail of admirers salivating. Utterly delicious.\"\n",
    "# description = \"Temperance suggests a period of balance and harmony in your life, with the Eight of Wands representing rapid movement and progress, while Strength signifies courage and inner strength. This combination of cards suggests that you are in a period of great growth and transformation, and while the journey may be difficult and unpredictable, you have the courage, strength and balance to take the steps necessary to achieve success.\"\n",
    "\n",
    "Card_1 = \"The Nine of Pentacles\"\n",
    "Card_2 = \"The Chariot\"\n",
    "Card_3 = \"The Hermit\"\n",
    "description = \"The Nine of Pentacles indicates that you are in a place of abundance and security, and you are able to enjoy the fruits of your labor. The Chariot indicates that you are in a place of power and control, and you are able to take charge of your life and make the necessary changes to ensure that you are able to reach your goals. The Hermit indicates that you are in a place of contemplation and reflection, and you are able to take a step back and look at the bigger picture. You are able to see the opportunities that are available to you and you are able to make the necessary changes to ensure that you are able to reach your goals.\"\n",
    "\n",
    "# Card_1 = \"Eight of Swords\"\n",
    "# Card_2 = \"The Lovers\"\n",
    "# Card_3 = \"The High Priestess\"\n",
    "# description = \"The Eight of Swords indicates that you are in a period of feeling trapped and stuck in a situation that is not allowing you to move forward. The Lovers card suggests that you are in a place of making a decision that will have a significant impact on your life. The High Priestess card indicates that you are in a place of deep contemplation and reflection, and that you are in a place of understanding the deeper meaning of the situation. You are in a place of understanding the importance of taking the time to reflect and make the right decision for yourself.\"\n",
    "\n",
    "# Card_1 = \"Death\"\n",
    "# Card_2 = \"The Fool\"\n",
    "# Card_3 = \"The King of Swords\"\n",
    "# description = \"The Death card indicates that you are in a period of transformation and change. The Fool card indicates that you are in a place of new beginnings and that you are ready to take a leap of faith and start a new journey. The King of Swords indicates that you are in a place of clarity and understanding, and that you are able to make decisions with a clear head and a strong sense of purpose. You are in a place of strength and courage, and you are ready to take on any challenge that comes your way.\"\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"Cards:\\n\", Card_1,\",\", Card_2,\",\", Card_3)\n",
    "    print(\"\\n\\nTarot Reading: \\n\", description, \"\\n\\n\")\n",
    "    prompt = generate_optimization_prompt(description)\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=1000)\n",
    "    perfume_description = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    perfume_description = perfume_description[len(prompt)-2:]\n",
    "    print(\"\\n\\nPerfume description:\\n\", perfume_description, \"\\n\\n\")\n",
    "\n",
    "    # description = \"The Temperance perfume is a harmonious blend of the Eight of Wands and Strength tarot cards. This fragrance captures the essence of balance and harmony, with notes of sweet honey and warm vanilla, combined with the freshness of citrus and herbs. The result is a complex and intriguing scent that is both calming and invigorating, perfect for those seeking to find their inner strength and balance. The Temperance perfume is a reminder that even in the midst of change and transformation, we have the power to stay grounded and centered, and to move forward with courage and determination.\"\n",
    "    prompt = generate_inference_prompt(perfume_description)\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=1000)\n",
    "\n",
    "    notes = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    notes = notes[len(prompt)-2:].strip()\n",
    "    print(f\"\\n\\nPerfume imgredients: \\n {notes}\", \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
